%!TEX root = ../Thesis.tex
\chapter{Discussion}\label{cha:discussion}

% \section{Balanced datasets}
    
% Acquiring a balanced dataset, cite Tarassenko L. 

% "When building a dataset for training a data-driven model, it is important that data are acquired as uniformly as possible over the system’s entire operating range. A jet engine spends much of its time operating at “cruise” conditions, with much less time spent operating under takeoff or landing conditions. If training data were drawn randomly from the entire flight, then this would result in a strong bias toward cruise conditions, simply because there would be many more feature vectors derived from periods of cruise operation. A balanced dataset is constructed by rejecting feature vectors during steady-state conditions if the change in engine speed with respect to that associated with the previous feature vector is below a given threshold. The effect of this is shown in Figure 1, in which a histogram of feature vector speeds from the original dataset shows a very dominant peak in the range from 80 to $85\%$ of maximum shaft speed, corresponding to cruise conditions. After rejection of consecutive feature vectors with similar speeds, the distribution is much more uniform across the whole speed range. This type of approach is used"

% To acquire a balanced dataset all samples where the plant is not operable is removed. But I need to make sure I don't remove data where one needle is stuck but the other one is operated! Hence both need to be zero for me to remove the sample! 
% add figure or table showing the number of samples each day as the number of process variables are increased. 
\section{Analyzing the data and building a case}
     Several issues arose once starting working with the data. A problem which most likely is relevant to most industries today is that having data is far from having good data. Starting working with the thesis, having 90Gb of data available seemed like more than enough. However, as the work progressed it became apparent that finding good cases for condition monitoring in the dataset was not straight forward. As it became clear that very few variable were sampled simultaneously, at a higher rate than hourly, much time was spent finding a case for condition monitoring. It might be possible that the energy company is sampling data in a scheme similar to the one used in \cite{cmfd paper}, but without having information about this, only having the data makes it very hard to verify. Even if one choose to sample data in several different ways, it would be beneficial to sample more data at a higher and constant frequency.
     
     Going through the logs from the power plants, the Pelton needle case was quickly picked out as interesting. As my project thesis focused on the guide vanes of Francis turbines, building a case around the Pelton needles would serve as a natural extension, where some one of the methods used for the Francis case could be tested on a new case. It would have been interesting to include more than just the needle variables in the analysis, but this was not possible due to the data. The methods used in the analysis can handle more variables, hence the analysis can be extended if the data allows it.     
    
    \subsection{Energy company}
        Using data from a third party turned out to be challenging. If Hymatek had collected the data, then getting information about how and why the data is sampled would have been much simpler. This is however a valuable experience, and the experineces can be used when Hymatek starts its own data collection. 

    

\section{Choosing the methods}
    Several methods and techniques were considered for the condition monitoring. The most important factor was to find methods that could be used with only normal data. As the Pelton case only had one reported incident, it made making a labeled data set hard. Unsupervised methods are much easier to train, as one does not have to collect data from all the different failure modes. As mentioned in the introduction, unsupervised methods also opens the possibility to detect unknown failure modes. This means that supervised and unsupervised does not exclude one another, and for a complete condition monitoring system using both approaches might yield the best solution. One class SVM was chosen because it  showed promise in the case with the Francis turbines guide vanes. Kernel density estimation was picked because it is a relatively simple method, which is fast to implement through scikit-learn. The long short term memory recurrent neural network algorithm was picked because it has shown promise when working with time series, and would serve well for comparison for the less complex other methods.  
    
\section{Hyperparameterization}
    The optimal set of hyperparameters were searched for through a grid search for the three methods. The parameters were found using data from plant 1, and the same paramaters were used for all the different training sets. This was done to see how well the methods would transfer between plants. If one needs to search for the optimal hyperparameters for each plant, then it will not be possible to simply deploy a pre-trained anomaly detection system. KDE and LSTM RNN showed promise for this as they performed very well on data from both plants. The one class SVM did hower show signs of beeing more dependent on being optmized on data from the same plant as it is trained on. 
    
    A more extensive search for the optimal set of hyperparameters could have been perfored, especially for one class SVM and LSTM RNN, but as the goal of this thesis was to investigate possible methods that could be used for condition monitoring, the parameterization found yielded good enough results. Before any of the methods can be deployd at an actuall plant, much more testing will need to be performed. 
    

\section{Training sets and test cases}
    Many different approaches could have been taken with the training sets and test cases. The main motivation for the chosen setup, was that it enabled to compare performance across plants and training sizes. Many more cases could have been created, but as mentioned earlier this is an initial study, that can be used as starting ground for further testing if the results are found promising enough by Hymatek. 




\section{Performance of the algorithms}
    how well do they perform?
    difference between the methods?
    problems with the methods?
    transferability between plants? 
    scaling of the data, why and how important is it? 
    
    For the anomaly scorers the extreme values seen for the day of the incident could mean that instead of having one threshold one could have stages of anomalous operation. 
    
    
    The Pelton needle case was chosen for further analysis for several reasons. Firstly itis a critical part of the Pelton turbine, if the needles are not operating as they shouldit will affect the power produced by the turbine. The needle openings are a big partof a complex control-system, and controls that the turbine holds constant speed. Ifa method can be found that could give early warnings about the above mentionedincident, maintenance can be planned and components can be overhauled before thesystem condition becomes so bad that it is no longer controllable. Secondly, havingdata from different plants makes it possible to analyze how well the methods andtechniques used adapt to new data. This is an important factor, if one can develop amethod that is transferable with little to no adaptation need between plants, the timefor commissioning will be greatly reduced.
    
    \subsection{SVM}
        discuss the fitting of the boundary, use of different kernels that better fit the wanted boundary. 
    
\section{Implementation at plants}
    what needs to be done before this can be used on a powerplant? How can it be used? discuss around the topic. 
    
    
\section{Challenges}
    

    
